{"cells":[{"cell_type":"markdown","metadata":{"id":"4eiqemuYiBmx"},"source":["# Dependencies"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5rabxM4viBmz"},"outputs":[],"source":["import os\n","import cv2\n","import math\n","import numpy as np\n","import seaborn as sns\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","\n","from keras.layers import *\n","import tensorflow.keras.backend as K\n","from keras.optimizers import Adam, SGD\n","from datetime import datetime, timedelta\n","from sklearn.metrics import confusion_matrix\n","from keras.utils import to_categorical, plot_model\n","from keras.models import Sequential, Model, load_model\n","from keras.callbacks import ModelCheckpoint, EarlyStopping"]},{"cell_type":"markdown","metadata":{"id":"cRw2ZHGIiBm0"},"source":["# Data Preparation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BsFsdDehiBm1"},"outputs":[],"source":["# Mount to Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# G-Drive Path\n","dataset_path = \"/content/drive/MyDrive/Skripsi/Dataset\"\n","save_file_path = \"/content/drive/MyDrive/Skripsi/File_Save\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PSODXEW1XjNE"},"outputs":[],"source":["# count dataset total\n","def count_files(directory):\n","    return len([name for name in os.listdir(directory) if os.path.isfile(os.path.join(directory, name))])\n","\n","# Initialize the total amount for theft and normal classes\n","total_pencurian = 0\n","total_normal = 0\n","\n","# Initialize the amount per category\n","kategori_pencurian = {'Gedung': 0, 'Ritel': 0, 'Motor': 0}\n","kategori_normal = {'Gedung': 0, 'Ritel': 0, 'Motor': 0}\n","\n","# Loop for each category and subcategory\n","for category in ['Pencurian', 'Normal']:\n","    for subcategory in ['Gedung', 'Ritel', 'Motor']:\n","        directory = os.path.join(dataset_path, category, subcategory)\n","        file_count = count_files(directory)\n","\n","        if category == 'Pencurian':\n","            total_pencurian += file_count\n","            kategori_pencurian[subcategory] += file_count\n","        else:\n","            total_normal += file_count\n","            kategori_normal[subcategory] += file_count\n","\n","# Print Result\n","print(f\"Total video kelas Pencurian\\t: {total_pencurian}\")\n","print(f\"Total video kelas Normal\\t: {total_normal}\")\n","print(\"\\nJumlah video Pencurian per-kategori:\")\n","for subcategory, count in kategori_pencurian.items():\n","    print(f\"  {subcategory}: {count}\")\n","print(\"\\nJumlah video Normal per-kategori:\")\n","for subcategory, count in kategori_normal.items():\n","    print(f\"  {subcategory}: {count}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DE2zwlq23sEJ"},"outputs":[],"source":["IMAGE_HEIGHT = 120\n","IMAGE_WIDTH = 160\n","SEQUENCE_COUNT = 20 # frames count for capture video\n","BATCH_SIZE = 2\n","\n","'''\n","  Batch_size is the number of data samples processed by the model in one\n","  training iteration. A larger batch_size uses more memory, but training\n","  process can be faster and more stable.\n","'''"]},{"cell_type":"markdown","metadata":{"id":"Jo1nHgHqiBm1"},"source":["# Preprocessing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RdBN_3WSiBm1"},"outputs":[],"source":["# function for split dataset to train, valiation, and test\n","def split_dataset(data_path, train_num=30, val_num=3, test_num=2):\n","  train_files = []\n","  val_files = []\n","  test_files = []\n","\n","  for root, _, files in os.walk(data_path): # loop for all dataset file path\n","    for idx, file in enumerate(files): # loop for file video name\n","      video_path = os.path.join(root, file) # spesific dataset file path\n","\n","      # get file path\n","      if idx < train_num:\n","        train_files.append(video_path)\n","      elif idx < train_num + val_num:\n","        val_files.append(video_path)\n","      elif idx < train_num + val_num + test_num:\n","        test_files.append(video_path)\n","\n","      # else:\n","        # test_files.append(video_path)\n","\n","    # Check for duplicates\n","    all_paths = train_files + val_files + test_files\n","    unique_paths = set(all_paths)\n","\n","    # Check if there are duplicates\n","    if len(all_paths) != len(unique_paths):\n","      print(\"Warning: Duplicate paths found!\")\n","\n","  return train_files, val_files, test_files"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SlPb8KZZuZWv"},"outputs":[],"source":["# function for labeling image\n","def labeling_img(video_path):\n","  file_name = os.path.basename(video_path) # get file video name\n","  file_name = file_name.split()[0] # take the first word\n","\n","  if file_name == 'normal': # class: 0 for normal, 1 for pencurian\n","    label = 0\n","  else:\n","    label = 1\n","\n","  return label"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zgitCws8ubCw"},"outputs":[],"source":["# Function for get video frames\n","def get_video_frame(video_path, resize=(320, 240), sequence_count=20):\n","  # get frames and labels list\n","  frames = []\n","  labels = []\n","\n","  video_reader = cv2.VideoCapture(video_path)\n","  frames_count = int(video_reader.get(cv2.CAP_PROP_FRAME_COUNT))\n","  skip_frames = max(int(frames_count/sequence_count), 1) # set the value to 1 if the quotient is negative\n","\n","  for frame_counter in range(sequence_count):\n","    # set the current frame position of the video.\n","    video_reader.set(cv2.CAP_PROP_POS_FRAMES, frame_counter * skip_frames)\n","\n","    # read the video frame.\n","    success, frame = video_reader.read()\n","\n","    # check if Video frame is not successfully read then break the loop\n","    if not success:\n","        break\n","\n","    # convert image color format\n","    frame = frame[:, :, [2, 1, 0]]\n","    '''\n","      OpenCV uses the BGR (Blue, Green, Red) image color format,\n","      so it needs to be converted to RGB (Red, Green, Blue) before modeling\n","      process.\n","    '''\n","\n","    # resize image\n","    frame = cv2.resize(frame, resize)\n","\n","    # append the normalized frame into the frames list\n","    frames.append(frame)\n","\n","    # call function labeling image\n","    # label = labeling_img(video_path)\n","    # labels.append(label)\n","\n","  video_reader.release()\n","  # return frames, labels\n","  return frames"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tKsXkQkbiBm3"},"outputs":[],"source":["# function for normalize pixel with range 0-1\n","def normalization_pixel(get_image):\n","  get_image = get_image.astype(np.float32) # convert integer to float\n","  normalized_image = get_image / 255.0 # normalize pixelz\n","  return normalized_image"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PoKJ2sbl3OHA"},"outputs":[],"source":["# split dataset path for train, validation, and test\n","train_path, val_path, test_path = split_dataset(dataset_path, train_num=30, val_num=3, test_num=2)\n","\n","# ======================= Process The Images and Labels ========================\n","# list image frame\n","train_frames = []\n","val_frames = []\n","test_frames = []\n","\n","# list image labels\n","train_labels = []\n","val_labels = []\n","test_labels = []\n","\n","# get images and labels train\n","for path in train_path:\n","  frame = get_video_frame(video_path=path, resize=(IMAGE_WIDTH, IMAGE_HEIGHT), sequence_count=SEQUENCE_COUNT)\n","  if len(frame) == SEQUENCE_COUNT: # check frame are the same as count of sequences\n","    train_frames.append(frame)\n","\n","    # call function labeling image\n","    label = labeling_img(path)\n","    train_labels.append(label)\n","\n","# get images and labels validation\n","for path in val_path:\n","  frame = get_video_frame(video_path=path, resize=(IMAGE_WIDTH, IMAGE_HEIGHT), sequence_count=SEQUENCE_COUNT)\n","  if len(frame) == SEQUENCE_COUNT: # check frame are the same as count of sequences\n","    val_frames.append(frame)\n","\n","    # call function labeling image\n","    label = labeling_img(path)\n","    val_labels.append(label)\n","\n","# get images and labels test\n","for path in test_path:\n","  frame = get_video_frame(video_path=path, resize=(IMAGE_WIDTH, IMAGE_HEIGHT), sequence_count=SEQUENCE_COUNT)\n","  if len(frame) == SEQUENCE_COUNT: # check frame are the same as count of sequences\n","    test_frames.append(frame)\n","\n","    # call function labeling image\n","    label = labeling_img(path)\n","    test_labels.append(label)\n","\n","# convert list images to numpy array\n","train_labels = np.array(train_labels)\n","val_labels = np.array(val_labels)\n","test_labels = np.array(test_labels)\n","\n","# convert list labels to numpy array\n","train_frames = np.array(train_frames)\n","val_frames = np.array(val_frames)\n","test_frames = np.array(test_frames)\n","\n","# show image shape\n","print(\"Training shape images:\", train_frames.shape)\n","print(\"Valiation shape images:\", val_frames.shape)\n","print(\"Testing shape images:\", test_frames.shape)\n","\n","# show labels shape\n","print(\"\\nTraining shape labels:\", train_labels.shape)\n","print(\"Valiation shape labels:\", val_labels.shape)\n","print(\"Testing shape labels:\", test_labels.shape)\n","\n","# convert label to one-hot-encoding\n","train_labels = to_categorical(train_labels)\n","val_labels = to_categorical(val_labels)\n","test_labels = to_categorical(test_labels)\n","\n","# show one-hot-encoding labels shape\n","print(\"\\nTraining shape one-hot-encoding labels:\", train_labels.shape)\n","print(\"Valiation shape one-hot-encoding labels:\", val_labels.shape)\n","print(\"Testing shape one-hot-encoding labels:\", test_labels.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-TTbAd1wSR64"},"outputs":[],"source":["# Normalize pixel with range 0-1\n","train_frames_norm = normalization_pixel(train_frames)\n","val_frames = normalization_pixel(val_frames)\n","test_frames = normalization_pixel(test_frames)\n","\n","# Print pixel range comparison\n","print(f\"Range before normalization:\\nmin: {np.min(train_frames)}\\nmax: {np.max(train_frames)}\")\n","print(f\"\\nRange after normalization:\\nmin: {np.min(train_frames_norm)}\\nmax: {np.max(train_frames_norm)}\")"]},{"cell_type":"markdown","metadata":{"id":"UBmzwp1JiBm4"},"source":["# Modeling"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OvpXoNv7SQJU"},"outputs":[],"source":["# Fix Architecture\n","model_name = 'SelfBuild_CNN-LSTM' # name for save model\n","\n","model = Sequential()\n","\n","model.add(TimeDistributed(Conv2D(32, (3, 3), padding='same', activation='relu'),\n","                          input_shape=(SEQUENCE_COUNT, IMAGE_HEIGHT, IMAGE_WIDTH, 3)))\n","model.add(TimeDistributed(BatchNormalization()))\n","model.add(TimeDistributed(MaxPooling2D((2, 2))))\n","model.add(TimeDistributed(Dropout(0.25)))\n","\n","model.add(TimeDistributed(Conv2D(64, (3, 3), padding='same', activation='relu')))\n","model.add(TimeDistributed(BatchNormalization()))\n","model.add(TimeDistributed(MaxPooling2D((2, 2))))\n","model.add(TimeDistributed(Dropout(0.25)))\n","\n","model.add(TimeDistributed(Conv2D(128, (3, 3), padding='same', activation='relu')))\n","model.add(TimeDistributed(BatchNormalization()))\n","model.add(TimeDistributed(MaxPooling2D((2, 2))))\n","model.add(TimeDistributed(Dropout(0.25)))\n","\n","model.add(TimeDistributed(Flatten()))\n","model.add(LSTM(128, return_sequences=True))\n","model.add(LSTM(64))\n","# model.add(LSTM(128))\n","# model.add(Dense(128, activation='relu'))\n","# model.add(Dropout(0.50))\n","\n","model.add(Dense(2, activation='sigmoid'))\n","\n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"fFvvMWKelPYv"},"source":["### process architecture"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CH204yOGIb8n"},"outputs":[],"source":["# create folder for save the model\n","current_datetime = datetime.now() + timedelta(hours=7) # current Indonesia date and time (GMT +7)\n","\n","# set date format for main folder\n","date_format = '%y-%m-%d'\n","date = datetime.strftime(current_datetime, date_format)\n","\n","# set time format for sub-folder\n","# time_format = '%H:%M'\n","time_format = '%H_%M' # for windows\n","time = datetime.strftime(current_datetime, time_format)\n","\n","# create folder\n","model_save_folder = os.path.join(save_file_path, 'Model', date, f'{model_name}({time})') # folder path\n","os.makedirs(model_save_folder, exist_ok=True) # create folder if not exist\n","\n","# Save and Show the Architecture Model Graph Image\n","save_file = os.path.join(model_save_folder, f'architecture.jpg') # file path\n","plot_model(model, to_file=save_file, show_shapes=True, show_layer_names=True)"]},{"cell_type":"markdown","metadata":{"id":"MbhbOzMQvrAM"},"source":["# Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"da4ZgiV8TISQ"},"outputs":[],"source":["def Recall(y_true, y_pred):\n","    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n","    recall = true_positives / (possible_positives + K.epsilon())\n","    return recall\n","\n","def Precision(y_true, y_pred):\n","    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n","    precision = true_positives / (predicted_positives + K.epsilon())\n","    return precision\n","\n","def F1_Score(y_true, y_pred):\n","    precision = Precision(y_true, y_pred)\n","    recall = Recall(y_true, y_pred)\n","    return 2*((precision*recall)/(precision+recall+K.epsilon()))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ncOA6FE_6NCq"},"outputs":[],"source":["# Check device running on GPU\n","if tf.config.list_physical_devices('GPU'):\n","  print('GPU is available')\n","else:\n","  print('GPU is not available (USING CPU)')\n","\n","# Compile the model\n","model.compile(optimizer=Adam(learning_rate=0.0001),\n","              loss='binary_crossentropy',\n","              metrics=['Accuracy', 'Precision', 'Recall', F1_Score])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IweFIJj_vxK7"},"outputs":[],"source":["# save the best training model\n","best_model_path = os.path.join(model_save_folder, 'best_model.keras')\n","checkpoint = ModelCheckpoint(best_model_path, monitor='val_loss', save_best_only=True, mode='min', verbose=1)\n","\n","# early stopping when there was no significant improvement in the training process\n","early_stopping = EarlyStopping(monitor='val_loss', patience=4, mode='auto')\n","\n","# training the model\n","model_history = model.fit(x = train_frames_norm,\n","                          y = train_labels,\n","                          validation_data= (val_frames, val_labels),\n","                          epochs = 100,\n","                          batch_size = BATCH_SIZE,\n","                          callbacks=[checkpoint, early_stopping],\n","                          shuffle = True)\n","\n","# save the training model\n","model_save_path = os.path.join(model_save_folder, 'model.keras')\n","model.save(model_save_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n6QwIYT_9H94"},"outputs":[],"source":["# show plot model history\n","metrics = list(model_history.history.keys()) # get dictionary key\n","num_plot = int(len(metrics) / 2) # for get only train key\n","\n","_, axs = plt.subplots(1, num_plot, figsize=(30, 6)) # set canvas size\n","\n","for idx in range(num_plot):\n","  train_values = model_history.history[metrics[idx]]\n","  val_values = model_history.history[f'val_{metrics[idx]}']\n","\n","  # set up show plot data\n","  axs[idx].plot(train_values, label=f'train_{metrics[idx]}')\n","  axs[idx].plot(val_values, label=f'val_{metrics[idx]}')\n","  axs[idx].set_title(f'{metrics[idx]} model')\n","  axs[idx].set_xlabel('epoch')\n","  axs[idx].set_ylabel(f'{metrics[idx]}')\n","  axs[idx].legend()\n","\n","# save the plot\n","save_img = os.path.join(model_save_folder, 'plotting_metrics.jpg')\n","plt.savefig(save_img)\n","\n","# show ploting\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"-qn-TwVF2ZLy"},"source":["# Evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1RIWr3uNXHYa"},"outputs":[],"source":["# evaluate the model\n","model_eval = load_model(model_save_path, custom_objects={'F1_Score': F1_Score})\n","result_model_eval = model_eval.evaluate(test_frames, test_labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MtBIc7gNXJTJ"},"outputs":[],"source":["# evaluate the best model\n","best_model = load_model(best_model_path, custom_objects={'F1_Score': F1_Score})\n","result_best_model = best_model.evaluate(test_frames, test_labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wYpcqc5bppnH"},"outputs":[],"source":["# Model Report\n","def report_metrics_value(model, metric_key, metric_name, idx, note):\n","  for key in metric_key[:metric_name]:\n","    if key == 'f1_score':\n","      value = np.mean(model.history[key][idx])\n","    else:\n","      value = model.history[key][idx]\n","\n","    note.write('\\ttrain_{}\\t: {:.4}'.format(key, value))\n","\n","  note.write('\\n')\n","  for key in metric_key[metric_name:]:\n","    if key == 'val_f1_score':\n","      value = np.mean(model.history[key][idx])\n","    else:\n","      value = model.history[key][idx]\n","\n","    note.write('\\t{}\\t: {:.4}'.format(key, value))\n","\n","def report_eval(model, metric_key, note):\n","  for idx, value in enumerate(model):\n","    if isinstance(value, np.ndarray):\n","      value = np.mean(value)\n","\n","    note.write('\\t{}\\t: {:.4}'.format(metric_key[idx], value))\n","\n","# Save Files\n","save_report = os.path.join(model_save_folder, 'training_report.txt')\n","with open(save_report, 'w') as f:\n","  # Training report\n","  f.write(f'TRAINING REPORT📝\\n\\n')\n","  f.write(f'Image Size\\t\\t: {IMAGE_HEIGHT}(H) x {IMAGE_WIDTH}(W)\\n')\n","  f.write(f'Total Train Data\\t: {train_frames_norm.shape[0]}\\nTotal Valid Data\\t: {val_frames.shape[0]}\\nTotal Test Data\\t\\t: {test_frames.shape[0]}\\n')\n","  f.write(f'Frame Sequences\\t\\t: {SEQUENCE_COUNT}\\n')\n","  f.write(f'Batch Size\\t\\t: {BATCH_SIZE}\\n\\n')\n","\n","  f.write(f'Optimizer Name\\t: {model.optimizer.get_config()[\"name\"]}\\n')\n","  f.write('learning rate\\t: {:.5g}\\n'.format(model.optimizer.get_config()['learning_rate']))\n","\n","  config_str='\\n\\t'.join([f'{key}: {value}' for key, value in model.optimizer.get_config().items() if key != 'name' and key != 'learning_rate'])\n","  f.write(f'Optimizer Config:\\n\\t{config_str}\\n\\n')\n","\n","  f.write(f'Loss\\t: {model.loss}\\n')\n","  f.write(f'Metrics\\t: {metrics[1:num_plot]}\\n\\n')\n","\n","  f.write(f'Total Epoch\\t\\t: {model_history.params[\"epochs\"]}\\n')\n","  f.write(f'Step Per-Epoch\\t\\t: {model_history.params[\"steps\"]}\\n')\n","  try:\n","    f.write(f'Epoch Early Stopping\\t: {early_stopping.stopped_epoch}\\n')\n","  except:\n","    f.write(f'Epoch Early Stopping\\t: 0\\n')\n","\n","  idx = model_history.history['val_loss'].index(min(model_history.history['val_loss']))\n","  f.write(f'Best Model Epoch\\t: {idx+1}\\n\\n')\n","\n","  f.write('Training Model:\\n')\n","  report_metrics_value(model_history, metrics, num_plot, idx=-1, note=f)\n","\n","  f.write('\\n\\nTraining Best Model:\\n')\n","  report_metrics_value(model_history, metrics, num_plot, idx=idx, note=f)\n","\n","  # Evaluation Report\n","  f.write('\\n\\nEvaluation Model:\\n')\n","  report_eval(result_model_eval, metrics, f)\n","\n","  f.write('\\n\\nEvaluation Best Model:\\n')\n","  report_eval(result_best_model, metrics, f)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P7PC68aYZaWX"},"outputs":[],"source":["# get label predict and original\n","get_data = [train_frames, val_frames, test_frames]\n","get_labels = [train_labels, val_labels, test_labels]\n","titles = ['Train', 'Validation', 'Test']\n","name_confusion = 'Last Epoch Confusion Matrix'\n","\n","fig, axes = plt.subplots(1, 3, figsize=(21, 7))\n","fig.suptitle(name_confusion, fontsize=16)\n","\n","for idx, ax in enumerate(axes):\n","  model_predict = model_eval.predict(get_data[idx])\n","  label_predict = np.argmax(model_predict, axis=1)\n","  label_original = np.argmax(get_labels[idx], axis=1)\n","  conf_matrix = confusion_matrix(label_predict, label_original) # get confusion matrix\n","\n","  sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', ax=ax)\n","  ax.set_xlabel('Predicted labels')\n","  ax.set_ylabel('True labels')\n","  ax.set_title(titles[idx])\n","  ax.set_xticklabels(['Class 0', 'Class 1'])\n","  ax.set_yticklabels(['Class 0', 'Class 1'])\n","\n","# save the plot\n","save_img = os.path.join(model_save_folder, name_confusion + '.jpg')\n","plt.savefig(save_img)\n","\n","# show plot\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3Ic2DY_LzNiF"},"outputs":[],"source":["# get label predict and original\n","get_data = [train_frames, val_frames, test_frames]\n","get_labels = [train_labels, val_labels, test_labels]\n","titles = ['Train', 'Validation', 'Test']\n","name_confusion = 'Best Model Confusion Matrix'\n","\n","fig, axes = plt.subplots(1, 3, figsize=(21, 7))\n","fig.suptitle(name_confusion, fontsize=16)\n","\n","for idx, ax in enumerate(axes):\n","  model_predict = best_model.predict(get_data[idx])\n","  label_predict = np.argmax(model_predict, axis=1)\n","  label_original = np.argmax(get_labels[idx], axis=1)\n","  conf_matrix = confusion_matrix(label_predict, label_original) # get confusion matrix\n","\n","  sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', ax=ax)\n","  ax.set_xlabel('Predicted labels')\n","  ax.set_ylabel('True labels')\n","  ax.set_title(titles[idx])\n","  ax.set_xticklabels(['Class 0', 'Class 1'])\n","  ax.set_yticklabels(['Class 0', 'Class 1'])\n","\n","# save the plot\n","save_img = os.path.join(model_save_folder, name_confusion + '.jpg')\n","plt.savefig(save_img)\n","\n","# show plot\n","plt.tight_layout()\n","plt.show()"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["6V_dmbRm00Q8","A_TRgU2rbKbT","o1jzo6Llw7IX"],"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"}},"nbformat":4,"nbformat_minor":0}
