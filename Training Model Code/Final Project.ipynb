{"cells":[{"cell_type":"markdown","metadata":{"id":"4eiqemuYiBmx"},"source":["# Dependencies"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5rabxM4viBmz"},"outputs":[],"source":["import os\n","import cv2\n","import math\n","import numpy as np\n","import seaborn as sns\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import tensorflow.keras.backend as K\n","\n","from keras.layers import *\n","from keras.applications import VGG16, ResNet50\n","from keras.optimizers import Adam, SGD\n","from datetime import datetime, timedelta\n","from sklearn.metrics import confusion_matrix\n","from keras.utils import to_categorical, plot_model\n","from keras.models import Sequential, Model, load_model\n","from keras.callbacks import ModelCheckpoint, EarlyStopping"]},{"cell_type":"markdown","metadata":{"id":"cRw2ZHGIiBm0"},"source":["# Data Preparation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vGkygjcKiBm1"},"outputs":[],"source":["# Local Path (Windows)\n","# dataset_path = r\"E:\\Dataset Skripsi\\Dataset\" # Folder created manually\n","# save_file_path = r\"E:\\Dataset Skripsi\\File_Save\" # Folder can be created automatically"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BsFsdDehiBm1"},"outputs":[],"source":["# Mount to Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# G-Drive Path\n","dataset_path = \"/content/drive/MyDrive/Skripsi/Dataset\" # Folder created manually\n","save_file_path = \"/content/drive/MyDrive/Skripsi/File_Save\" # Folder can be created automatically"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PSODXEW1XjNE"},"outputs":[],"source":["# count dataset total\n","def count_files(directory):\n","    return len([name for name in os.listdir(directory) if os.path.isfile(os.path.join(directory, name))])\n","\n","# Initialize the total amount for theft and normal classes\n","total_pencurian = 0\n","total_normal = 0\n","\n","# Initialize the amount per category\n","kategori_pencurian = {'Gedung': 0, 'Ritel': 0, 'Motor': 0}\n","kategori_normal = {'Gedung': 0, 'Ritel': 0, 'Motor': 0}\n","\n","# Loop for each category and subcategory\n","for category in ['Pencurian', 'Normal']:\n","    for subcategory in ['Gedung', 'Ritel', 'Motor']:\n","        directory = os.path.join(dataset_path, category, subcategory)\n","        file_count = count_files(directory)\n","\n","        if category == 'Pencurian':\n","            total_pencurian += file_count\n","            kategori_pencurian[subcategory] += file_count\n","        else:\n","            total_normal += file_count\n","            kategori_normal[subcategory] += file_count\n","\n","# Print Result\n","print(f\"Total video kelas Pencurian\\t: {total_pencurian}\")\n","print(f\"Total video kelas Normal\\t: {total_normal}\")\n","print(\"\\nJumlah video Pencurian per-kategori:\")\n","for subcategory, count in kategori_pencurian.items():\n","    print(f\"  {subcategory}: {count}\")\n","print(\"\\nJumlah video Normal per-kategori:\")\n","for subcategory, count in kategori_normal.items():\n","    print(f\"  {subcategory}: {count}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DE2zwlq23sEJ"},"outputs":[],"source":["IMAGE_HEIGHT = 120\n","IMAGE_WIDTH = 160\n","SEQUENCE_COUNT = 30 # frames count for capture video\n","BATCH_SIZE = 9\n","\n","'''\n","  Batch_size is the number of data samples processed by the model in one\n","  training iteration. A larger batch_size uses more memory, but training\n","  process can be faster and more stable.\n","'''"]},{"cell_type":"markdown","metadata":{"id":"Jo1nHgHqiBm1"},"source":["# Preprocessing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RdBN_3WSiBm1"},"outputs":[],"source":["# function for split dataset to train, valiation, and test\n","def split_dataset(data_path, train_num=30, val_num=3, test_num=2):\n","  train_files = []\n","  val_files = []\n","  test_files = []\n","\n","  for root, _, files in os.walk(data_path): # loop for all dataset file path\n","    for idx, file in enumerate(files): # loop for file video name\n","      video_path = os.path.join(root, file) # spesific dataset file path\n","\n","      # get file path\n","      if idx < train_num:\n","        train_files.append(video_path)\n","      elif idx < train_num + val_num:\n","        val_files.append(video_path)\n","      elif idx < train_num + val_num + test_num:\n","        test_files.append(video_path)\n","\n","      # else:\n","        # test_files.append(video_path)\n","\n","    # Check for duplicates\n","    all_paths = train_files + val_files + test_files\n","    unique_paths = set(all_paths)\n","\n","    # Check if there are duplicates\n","    if len(all_paths) != len(unique_paths):\n","      print(\"Warning: Duplicate paths found!\")\n","\n","  return train_files, val_files, test_files"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SlPb8KZZuZWv"},"outputs":[],"source":["# function for labeling image\n","def labeling_img(video_path):\n","  file_name = os.path.basename(video_path) # get file video name\n","  file_name = file_name.split()[0] # take the first word\n","\n","  if file_name == 'normal': # class: 0 for normal, 1 for pencurian\n","    label = 0\n","  else:\n","    label = 1\n","\n","  return label"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HP4uhc30iBm2"},"outputs":[],"source":["# # function for get video frame to image (function_1: get video with interval in seconds)\n","# def get_video_frame(video_path, resize=(320, 240), frame_interval=1):\n","#   cap = cv2.VideoCapture(video_path)\n","#   fps = int(cap.get(cv2.CAP_PROP_FPS)) # get video fps\n","#   frame_count = 0\n","#   frames = []\n","#   labels = []\n","\n","#   while True:\n","#     ret, frame = cap.read()\n","\n","#     if not ret:\n","#       break\n","\n","#     # Capture images from the video at intervals specified in seconds\n","#     if frame_count % (fps*frame_interval) == 0:\n","#       frame = cv2.resize(frame, resize)\n","#       '''\n","#         OpenCV uses the BGR (Blue, Green, Red) image color format,\n","#         so it needs to be converted to RGB (Red, Green, Blue) before modeling\n","#         process.\n","#       '''\n","#       frame = frame[:, :, [2, 1, 0]] # convert image color format\n","#       frames.append(frame)\n","\n","#       # call function labeling image\n","#       label = labeling_img(video_path)\n","#       labels.append(label)\n","\n","#     frame_count += 1\n","\n","#   cap.release()\n","#   return frames, labels"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zgitCws8ubCw"},"outputs":[],"source":["# function for get video frame to image (function_2: get video with count of frames)\n","def get_video_frame(video_path, resize=(320, 240), sequence_count=20):\n","  # get frames and labels list\n","  frames = []\n","  labels = []\n","\n","  video_reader = cv2.VideoCapture(video_path)\n","  frames_count = int(video_reader.get(cv2.CAP_PROP_FRAME_COUNT))\n","  skip_frames = max(int(frames_count/sequence_count), 1) # set the value to 1 if the quotient is negative\n","\n","  for frame_counter in range(sequence_count):\n","    # set the current frame position of the video.\n","    video_reader.set(cv2.CAP_PROP_POS_FRAMES, frame_counter * skip_frames)\n","\n","    # read the video frame.\n","    success, frame = video_reader.read()\n","\n","    # check if Video frame is not successfully read then break the loop\n","    if not success:\n","        break\n","\n","    # convert image color format\n","    frame = frame[:, :, [2, 1, 0]]\n","    '''\n","      OpenCV uses the BGR (Blue, Green, Red) image color format,\n","      so it needs to be converted to RGB (Red, Green, Blue) before modeling\n","      process.\n","    '''\n","\n","    # resize image\n","    frame = cv2.resize(frame, resize)\n","\n","    # append the normalized frame into the frames list\n","    frames.append(frame)\n","\n","    # call function labeling image\n","    # label = labeling_img(video_path)\n","    # labels.append(label)\n","\n","  video_reader.release()\n","  # return frames, labels\n","  return frames"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tKsXkQkbiBm3"},"outputs":[],"source":["# function for normalize pixel with range 0-1\n","def normalization_pixel(get_image):\n","  get_image = get_image.astype(np.float32) # convert integer to float\n","  normalized_image = get_image / 255.0 # normalize pixelz\n","  return normalized_image"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g8u7Y-90iBm3"},"outputs":[],"source":["# function for show frames image (Optional)\n","def plot_images(images, main_title, rows=2, cols=4):\n","  # create a figure and a set of subplots\n","  fig, axes = plt.subplots(rows, cols, figsize=(12, 6))\n","\n","  # Set main title\n","  fig.suptitle(main_title, fontsize=16)\n","\n","  # iterate flattened array of axes\n","  for i, ax in enumerate(axes.flat):\n","    if i < len(images): # check if there are images to display\n","      ax.imshow(images[i], cmap='gray')\n","      ax.set_title(f'image_{i}')\n","\n","    ax.axis('off') # turn off axis lines and labels\n","\n","  plt.tight_layout() # adjust spacing between subplots\n","  plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Qt6VQCGHiBm2"},"outputs":[],"source":["# # function for save image and labels (this function is optional)\n","# def save_files(get_image, get_labels, path_save, type_file, folder_name=None):\n","#   # path for save image\n","#   if folder_name is None:\n","#     path = os.path.join(path_save, type_file)\n","#   else:\n","#     path = os.path.join(path_save, folder_name, type_file)\n","\n","#   os.makedirs(path, exist_ok=True) # create folder if not exist\n","\n","#   # save image\n","#   for idx, img in enumerate(get_image):\n","#     img = img[:, :, [2, 1, 0]] # convert image color format\n","\n","#     frame_name = f\"frame_{idx}.jpg\"\n","#     frame_path = os.path.join(path, frame_name)\n","#     cv2.imwrite(frame_path, img)\n","\n","#   # save labels\n","#   path_labels = os.path.join(path, f\"{type_file}.txt\")\n","#   with open(path_labels, 'w') as f:\n","#     for label in get_labels:\n","#       f.write(str(label) + '\\n')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s2iSih9nVyEM"},"outputs":[],"source":["# function for save image and labels (this function is optional) | For Input TimeDistributed\n","def save_files(get_image, get_labels, path_save, type_file, folder_name=None):\n","  # folder path for save image\n","  if folder_name is None:\n","    path = os.path.join(path_save, type_file)\n","  else:\n","    path = os.path.join(path_save, folder_name, type_file)\n","  os.makedirs(path, exist_ok=True) # create folder if not exist\n","\n","  for idx, (images, label) in enumerate(zip(get_image, get_labels)):\n","    frames_folder_path = os.path.join(path, f'frames_{idx}')\n","    os.makedirs(frames_folder_path, exist_ok=True) # create folder if not exist\n","\n","    # save image\n","    for idx2, img in enumerate(images):\n","      img = img[:, :, [2, 1, 0]] # convert image color format\n","\n","      frame_name = f\"frame_{idx}_{idx2}.jpg\"\n","      frame_path = os.path.join(frames_folder_path, frame_name)\n","      cv2.imwrite(frame_path, img)\n","\n","    # save labels\n","    path_labels = os.path.join(path, f\"{type_file}.txt\")\n","    if os.path.exists(path_labels) and idx == 0:\n","      os.remove(path_labels)\n","\n","    label_str = 1 if np.array_equal(label, [0, 1]) else 0\n","    with open(path_labels, 'a') as f:\n","      f.write(f'frames_{idx}: {label} {label_str}\\n')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ew61Y9HfiBm3"},"outputs":[],"source":["# # split dataset path for train, validation, and test (function_1)\n","# train_path, val_path, test_path = split_dataset(dataset_path, train_num=5)\n","\n","# # list image frame\n","# train_frames = []\n","# val_frames = []\n","# test_frames = []\n","\n","# # list image labels\n","# train_labels = []\n","# val_labels = []\n","# test_labels = []\n","\n","# interval = 2 # interval frame in second\n","\n","# # get images and labels train\n","# for path in train_path:\n","#   frame, label = get_video_frame(video_path=path, frame_interval=interval)\n","#   train_frames.extend(frame)\n","#   train_labels.extend(label)\n","\n","# # get images and labels validation\n","# for path in val_path:\n","#   frame, label = get_video_frame(video_path=path, frame_interval=interval)\n","#   val_frames.extend(frame)\n","#   val_labels.extend(label)\n","\n","# # get images and labels test\n","# for path in test_path:\n","#   frame, label = get_video_frame(video_path=path, frame_interval=interval)\n","#   test_frames.extend(frame)\n","#   test_labels.extend(label)\n","\n","# # convert list image to numpy array\n","# train_frames = np.array(train_frames)\n","# val_frames = np.array(val_frames)\n","# test_frames = np.array(test_frames)\n","\n","# # show image shape\n","# print(\"Training shape images:\", train_frames.shape)\n","# print(\"Valiation shape images:\", val_frames.shape)\n","# print(\"Testing shape images:\", test_frames.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ws3V40eNwKCx"},"outputs":[],"source":["# # split dataset path for train, validation, and test (function_2) | without list .extend()\n","# train_path, val_path, test_path = split_dataset(dataset_path, train_num=5)\n","\n","# # ======================= Process The Images and Labels ========================\n","# # list image frame\n","# train_frames = []\n","# val_frames = []\n","# test_frames = []\n","\n","# # list image labels\n","# train_labels = []\n","# val_labels = []\n","# test_labels = []\n","\n","# # get images and labels train\n","# for path in train_path:\n","#   frame, label = get_video_frame(video_path=path, resize=(IMAGE_WIDTH, IMAGE_HEIGHT), sequence_count=SEQUENCE_COUNT)\n","#   train_frames.extend(frame)\n","#   train_labels.extend(label)\n","\n","# # get images and labels validation\n","# for path in val_path:\n","#   frame, label = get_video_frame(video_path=path, resize=(IMAGE_WIDTH, IMAGE_HEIGHT), sequence_count=SEQUENCE_COUNT)\n","#   val_frames.extend(frame)\n","#   val_labels.extend(label)\n","\n","# # get images and labels test\n","# for path in test_path:\n","#   frame, label = get_video_frame(video_path=path, resize=(IMAGE_WIDTH, IMAGE_HEIGHT), sequence_count=SEQUENCE_COUNT)\n","#   test_frames.extend(frame)\n","#   test_labels.extend(label)\n","\n","# # convert list images to numpy array\n","# train_labels = np.array(train_labels)\n","# val_labels = np.array(val_labels)\n","# test_labels = np.array(test_labels)\n","\n","# # convert list labels to numpy array\n","# train_frames = np.array(train_frames)\n","# val_frames = np.array(val_frames)\n","# test_frames = np.array(test_frames)\n","\n","# # show image shape\n","# print(\"Training shape images:\", train_frames.shape)\n","# print(\"Valiation shape images:\", val_frames.shape)\n","# print(\"Testing shape images:\", test_frames.shape)\n","\n","# # show labels shape\n","# print(\"\\nTraining shape labels:\", train_labels.shape)\n","# print(\"Valiation shape labels:\", val_labels.shape)\n","# print(\"Testing shape labels:\", test_labels.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PoKJ2sbl3OHA"},"outputs":[],"source":["# split dataset path for train, validation, and test (function_2) | with list .append()\n","train_path, val_path, test_path = split_dataset(dataset_path, train_num=30, val_num=3, test_num=2)\n","\n","# ======================= Process The Images and Labels ========================\n","# list image frame\n","train_frames = []\n","val_frames = []\n","test_frames = []\n","\n","# list image labels\n","train_labels = []\n","val_labels = []\n","test_labels = []\n","\n","# get images and labels train\n","for path in train_path:\n","  frame = get_video_frame(video_path=path, resize=(IMAGE_WIDTH, IMAGE_HEIGHT), sequence_count=SEQUENCE_COUNT)\n","  if len(frame) == SEQUENCE_COUNT: # check frame are the same as count of sequences\n","    train_frames.append(frame)\n","\n","    # call function labeling image\n","    label = labeling_img(path)\n","    train_labels.append(label)\n","\n","# get images and labels validation\n","for path in val_path:\n","  frame = get_video_frame(video_path=path, resize=(IMAGE_WIDTH, IMAGE_HEIGHT), sequence_count=SEQUENCE_COUNT)\n","  if len(frame) == SEQUENCE_COUNT: # check frame are the same as count of sequences\n","    val_frames.append(frame)\n","\n","    # call function labeling image\n","    label = labeling_img(path)\n","    val_labels.append(label)\n","\n","# get images and labels test\n","for path in test_path:\n","  frame = get_video_frame(video_path=path, resize=(IMAGE_WIDTH, IMAGE_HEIGHT), sequence_count=SEQUENCE_COUNT)\n","  if len(frame) == SEQUENCE_COUNT: # check frame are the same as count of sequences\n","    test_frames.append(frame)\n","\n","    # call function labeling image\n","    label = labeling_img(path)\n","    test_labels.append(label)\n","\n","# convert list images to numpy array\n","train_labels = np.array(train_labels)\n","val_labels = np.array(val_labels)\n","test_labels = np.array(test_labels)\n","\n","# convert list labels to numpy array\n","train_frames = np.array(train_frames)\n","val_frames = np.array(val_frames)\n","test_frames = np.array(test_frames)\n","\n","# show image shape\n","print(\"Training shape images:\", train_frames.shape)\n","print(\"Valiation shape images:\", val_frames.shape)\n","print(\"Testing shape images:\", test_frames.shape)\n","\n","# show labels shape\n","print(\"\\nTraining shape labels:\", train_labels.shape)\n","print(\"Valiation shape labels:\", val_labels.shape)\n","print(\"Testing shape labels:\", test_labels.shape)\n","\n","# convert label to one-hot-encoding\n","train_labels = to_categorical(train_labels)\n","val_labels = to_categorical(val_labels)\n","test_labels = to_categorical(test_labels)\n","\n","# show one-hot-encoding labels shape\n","print(\"\\nTraining shape one-hot-encoding labels:\", train_labels.shape)\n","print(\"Valiation shape one-hot-encoding labels:\", val_labels.shape)\n","print(\"Testing shape one-hot-encoding labels:\", test_labels.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hBelWJfRiBm3"},"outputs":[],"source":["# show image original train (Optional)\n","ploting = train_frames.reshape(-1, IMAGE_HEIGHT, IMAGE_WIDTH, 3)[:8]\n","plot_images(ploting, 'Original Images')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"My68kC1EbEJn"},"outputs":[],"source":["# show image original valid (Optional)\n","ploting = val_frames.reshape(-1, IMAGE_HEIGHT, IMAGE_WIDTH, 3)[:8]\n","plot_images(ploting, 'Original Images')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vevmM984bEJn"},"outputs":[],"source":["# show image original test (Optional)\n","ploting = test_frames.reshape(-1, IMAGE_HEIGHT, IMAGE_WIDTH, 3)[:8]\n","plot_images(ploting, 'Original Images')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jh8CQA5piBm3"},"outputs":[],"source":["# Save Original Image and Labels (Optional)\n","folderNames = 'Video Frames'\n","save_files(train_frames, train_labels, save_file_path, folder_name=folderNames, type_file='Train') # for train\n","save_files(val_frames, val_labels, save_file_path, folder_name=folderNames, type_file='Validation') # for validation\n","save_files(test_frames, test_labels, save_file_path, folder_name=folderNames, type_file='Test') # for test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mLcjry3UiBm3"},"outputs":[],"source":["# Normalize pixel with range 0-1\n","train_frames_norm = normalization_pixel(train_frames)\n","val_frames = normalization_pixel(val_frames)\n","test_frames = normalization_pixel(test_frames)\n","\n","# Print pixel range comparison\n","print(f\"Range before normalization:\\nmin: {np.min(train_frames)}\\nmax: {np.max(train_frames)}\")\n","print(f\"\\nRange after normalization:\\nmin: {np.min(train_frames_norm)}\\nmax: {np.max(train_frames_norm)}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ztg_D87IiBm3"},"outputs":[],"source":["# show image after normalization (Optional)\n","ploting = train_frames_norm.reshape(-1, IMAGE_HEIGHT, IMAGE_WIDTH, 3)[:8]\n","plot_images(ploting, 'Normalization Images')"]},{"cell_type":"markdown","metadata":{"id":"6V_dmbRm00Q8"},"source":["## Augmentation (Tentatif)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AbBPus7SiBm2"},"outputs":[],"source":["# # function for augmented training image (keras)\n","# def image_augmentation(get_images, get_labels, save_path=None, batch_size=32):\n","#   # path to save if not None\n","#   if save_path is not None:\n","#     save_path = os.path.join(save_path, 'Augmentation')\n","#     os.makedirs(save_path, exist_ok=True) # create folder if not exist\n","\n","#   # initialize augmented image\n","#   datagen = ImageDataGenerator(\n","#     rotation_range=10,\n","#     width_shift_range=0.1,\n","#     height_shift_range=0.1,\n","#     shear_range=0.1,\n","#     zoom_range=0.1,\n","#     horizontal_flip=True,\n","#     fill_mode='nearest',\n","#     rescale=1./255)\n","\n","#   # return the augmentation data\n","#   return datagen.flow(\n","#     x=get_images,\n","#     y=get_labels,\n","#     save_to_dir=save_path,\n","#     save_prefix='augmented',\n","#     batch_size=batch_size,\n","#     shuffle=False,\n","#     seed=42)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Tdoo7B5l8bxF"},"outputs":[],"source":["# # augmented train image\n","# train_frames_aug = image_augmentation(reshape_train_frames,\n","#                                 reshape_train_labels,\n","#                                 batch_size=BATCH_SIZE)\n","\n","# # =============== Check The Images and Labels After Augmentation ===============\n","# # get all augmented image\n","# aug_frames = []\n","# aug_labels = []\n","\n","# # iterate images according to batch size\n","# for _ in range(len(reshape_train_frames) // BATCH_SIZE + 1):\n","#   batch_data, labels_data = train_frames_aug.next() # get image and labels in generator\n","\n","#   # break if batch_data is none\n","#   if batch_data.shape[0] == 0:\n","#     break;\n","\n","#   # save image array to list\n","#   aug_frames.extend(batch_data)\n","#   aug_labels.extend(labels_data)\n","\n","# # convert list to numpy array\n","# aug_frames = np.array(aug_frames)\n","\n","# # show image shape and range pixel\n","# print(\"Training augmentation shape images:\", aug_frames.shape)\n","# print(f\"\\nAugmentation Pixel Image Range:\\nmin: {np.min(batch_data)}\\nmax: {np.max(batch_data)}\")\n","# print(f'\\nAugmented Labels Number: {len(aug_labels)}')\n","\n","# # check the augmented label same or not as original labels\n","# if np.array_equal(aug_labels, train_labels):\n","#     print('The augmented labels and the original labels are the same')\n","# else:\n","#     print('The augmented labels and the original labels are different')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bLVjxbfKX5IO"},"outputs":[],"source":["# save the Augmentation Images and Labels\n","# save_files(np.uint8(aug_frames * 255), aug_labels, save_file_path, type_file='Augmentation')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gdLCxB63iBm4"},"outputs":[],"source":["# show image augmentation\n","# plot_images(aug_frames[:8])"]},{"cell_type":"markdown","metadata":{"id":"UBmzwp1JiBm4"},"source":["# Modeling"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HNwGlAjibEJp"},"outputs":[],"source":["# Function for get CNN filters\n","# def model_filters(layer):\n","#   filters, bias = layer.get_weights()\n","#   n_filters = filters.shape[-1]\n","#   n_channels = filters.shape[-2]\n","\n","#   print(f'{layer.name}_bias:\\n{bias}')\n","#   plt.figure(figsize=(n_channels*3, n_filters*3))\n","#   for i in range(n_filters):\n","#     for j in range(n_channels):\n","#       ax = plt.subplot(n_filters, n_channels, i*n_channels + j + 1)\n","#       ax.set_xticks([])\n","#       ax.set_yticks([])\n","\n","#       plt.xlabel(f'depth_{j}') # set x label (filter depth)\n","#       if j == 0:\n","#         plt.ylabel(f'feture_map_{i}') # set y label (feture_map indeks)\n","#       plt.imshow(filters[:, :, j, i], cmap='gray')\n","\n","#       # show text\n","#       # filter_value = filters[:, :, j]\n","#       # for x in range(filter_value.shape[0]):\n","#       #   for y in range(filter_value.shape[1]):\n","#       #     plt.text(y, x, filter_value[x, y, j], color='red', fontsize=6, ha='center', va='center')\n","\n","#   plt.tight_layout()\n","#   plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Azdn4LNObEJp"},"outputs":[],"source":["# Function for get CNN features_map\n","# def feature_map(img_path, model, idx_model):\n","#   layer = model.layers[idx_model]\n","\n","#   # image preprocessing\n","#   image = cv2.imread(img_path)\n","#   image = image[:, :, [2, 1, 0]]\n","#   image = cv2.resize(image, (IMAGE_WIDTH, IMAGE_HEIGHT))\n","#   image = normalization_pixel(image)\n","\n","#   image = np.expand_dims(image, axis=0)\n","#   image = np.repeat(image, SEQUENCE_COUNT, axis=0)\n","#   image = image[np.newaxis, :]\n","\n","#   layer_predict = Model(inputs=model.inputs, outputs=layer.output)\n","#   features_map = layer_predict.predict(image)\n","\n","#   num_features = features_map.shape[-1]\n","#   num_rows = math.ceil(math.sqrt(num_features))\n","#   num_cols = math.ceil(num_features / num_rows)\n","#   plt.figure(figsize=(num_rows*3, num_cols*3))\n","\n","#   for i in range(num_features):\n","#     plt.subplot(num_rows, num_cols, i+1)\n","#     plt.imshow(features_map[0, 0, :, :, i], cmap='gray')\n","#     plt.axis('off')\n","#     plt.title(f'feature_map_{i}')\n","\n","#   plt.tight_layout()\n","#   plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-1L1shhyiBm4"},"outputs":[],"source":["# Load pre-trained VGG16 model without top (fully connected layers)\n","model_name = 'VGG16_CNN-LSTM' # name for save model\n","\n","# Load pre-trained VGG16 model without top (fully connected layers)\n","vgg_model = VGG16(weights='imagenet', include_top=False)\n","\n","# Freeze the weights of the VGG16 model\n","for layer in vgg_model.layers:\n","    layer.trainable = False\n","\n","# Create CNN-LSTM model\n","model = Sequential()\n","\n","# Add VGG16 model to the sequential model\n","model.add(TimeDistributed(vgg_model, input_shape=(SEQUENCE_COUNT, IMAGE_HEIGHT, IMAGE_WIDTH, 3)))\n","\n","# Add Global Average Pooling\n","model.add(TimeDistributed(GlobalAveragePooling2D()))\n","\n","# Add LSTM layers\n","# model.add(TimeDistributed(Flatten()))\n","model.add(LSTM(256))\n","\n","# Add final dense layers\n","model.add(Dense(2, activation='sigmoid'))\n","\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZU-SEsN1VMOJ"},"outputs":[],"source":["model_name = 'SelfBuild_CNN-LSTM' # name for save model\n","\n","model = Sequential()\n","\n","model.add(TimeDistributed(Conv2D(16, (3, 3), padding='same',activation = 'relu'),\n","                          input_shape = (SEQUENCE_COUNT, IMAGE_HEIGHT, IMAGE_WIDTH, 3)))\n","\n","model.add(TimeDistributed(MaxPooling2D((4, 4))))\n","model.add(TimeDistributed(Dropout(0.25)))\n","\n","model.add(TimeDistributed(Conv2D(32, (3, 3), padding='same',activation = 'relu')))\n","model.add(TimeDistributed(MaxPooling2D((4, 4))))\n","model.add(TimeDistributed(Dropout(0.25)))\n","\n","model.add(TimeDistributed(Conv2D(64, (3, 3), padding='same',activation = 'relu')))\n","model.add(TimeDistributed(MaxPooling2D((2, 2))))\n","model.add(TimeDistributed(Dropout(0.25)))\n","\n","model.add(TimeDistributed(Conv2D(64, (3, 3), padding='same',activation = 'relu')))\n","model.add(TimeDistributed(MaxPooling2D((2, 2))))\n","#model.add(TimeDistributed(Dropout(0.25)))\n","\n","model.add(TimeDistributed(Flatten()))\n","model.add(LSTM(32))\n","model.add(Dense(2, activation = 'sigmoid'))\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OvpXoNv7SQJU"},"outputs":[],"source":["model_name = 'SelfBuild_CNN-LSTM' # name for save model\n","\n","model = Sequential()\n","\n","model.add(TimeDistributed(Conv2D(32, (3, 3), padding='same', activation='relu'),\n","                          input_shape=(SEQUENCE_COUNT, IMAGE_HEIGHT, IMAGE_WIDTH, 3)))\n","model.add(TimeDistributed(BatchNormalization()))\n","model.add(TimeDistributed(MaxPooling2D((2, 2))))\n","model.add(TimeDistributed(Dropout(0.25)))\n","\n","model.add(TimeDistributed(Conv2D(64, (3, 3), padding='same', activation='relu')))\n","model.add(TimeDistributed(BatchNormalization()))\n","model.add(TimeDistributed(MaxPooling2D((2, 2))))\n","model.add(TimeDistributed(Dropout(0.25)))\n","\n","model.add(TimeDistributed(Conv2D(128, (3, 3), padding='same', activation='relu')))\n","model.add(TimeDistributed(BatchNormalization()))\n","model.add(TimeDistributed(MaxPooling2D((2, 2))))\n","model.add(TimeDistributed(Dropout(0.25)))\n","\n","model.add(TimeDistributed(Flatten()))\n","model.add(LSTM(128, return_sequences=True))\n","model.add(LSTM(64))\n","# model.add(LSTM(128))\n","# model.add(Dense(128, activation='relu'))\n","# model.add(Dropout(0.50))\n","\n","model.add(Dense(2, activation='sigmoid'))\n","\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NqMQqXfilOw3"},"outputs":[],"source":["model_name = 'ResNet50' # name for save model\n","\n","resnet_model = ResNet50(weights='imagenet', include_top=False, input_shape=(IMAGE_HEIGHT, IMAGE_WIDTH, 3))\n","\n","# Freeze ResNet layers\n","for layer in resnet_model.layers:\n","  layer.trainable = False\n","\n","model = Sequential()\n","model.add(TimeDistributed(resnet_model, input_shape=(SEQUENCE_COUNT, IMAGE_HEIGHT, IMAGE_WIDTH, 3)))\n","model.add(TimeDistributed(Flatten()))\n","model.add(LSTM(256, return_sequences=False))\n","model.add(Dense(128, activation='relu'))\n","model.add(Dropout(0.25))\n","model.add(Dense(2, activation='sigmoid'))\n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"fFvvMWKelPYv"},"source":["### process architecture"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CH204yOGIb8n"},"outputs":[],"source":["# create folder for save the model\n","current_datetime = datetime.now() + timedelta(hours=7) # current Indonesia date and time (GMT +7)\n","# current_datetime = datetime.now() # for windows\n","\n","# set date format for main folder\n","date_format = '%y-%m-%d'\n","date = datetime.strftime(current_datetime, date_format)\n","\n","# set time format for sub-folder\n","# time_format = '%H:%M'\n","time_format = '%H_%M' # for windows\n","time = datetime.strftime(current_datetime, time_format)\n","\n","# create folder\n","model_save_folder = os.path.join(save_file_path, 'Model', date, f'{model_name}({time})') # folder path\n","os.makedirs(model_save_folder, exist_ok=True) # create folder if not exist\n","\n","# Save and Show the Architecture Model Graph Image\n","save_file = os.path.join(model_save_folder, f'architecture.jpg') # file path\n","plot_model(model, to_file=save_file, show_shapes=True, show_layer_names=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xDij2dqbbEJq"},"outputs":[],"source":["# Show CNN Filter (Optional)\n","# print('Model Indeks:')\n","# for idx, layer in enumerate(model.layers):\n","#   if 'time_distributed' not in layer.name or len(layer.get_weights()) != 2:\n","#     if len(layer.output.shape) == 5:\n","#       print(idx, layer.name, len(layer.get_weights()), '(Only For Show Feature_Map)')\n","#     continue\n","#   # if 'conv' not in layer.name:\n","#   #   continue\n","\n","#   print(idx, layer.name, layer.get_weights()[0].shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-w6Gq7InbEJr"},"outputs":[],"source":["# Show CNN Features_Map (Optional)\n","# model_idx = 8\n","\n","# # if len(model.layers[model_idx].get_weights()) == 2:\n","# #   model_filters(model.layers[model_idx])\n","\n","# img_path = save_file_path + '/frame_0_0.jpg'\n","# feature_map(img_path, model, model_idx)"]},{"cell_type":"markdown","metadata":{"id":"MbhbOzMQvrAM"},"source":["# Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BwD543r1Eqyr"},"outputs":[],"source":["# def plot_history(history):\n","#   metrics = list(history.history.keys()) # get dictionary key\n","#   num_plot = int(len(metrics) / 2) # for get only train key\n","\n","#   _, axs = plt.subplots(1, num_plot, figsize=(30, 6)) # set canvas size\n","\n","#   for idx in range(num_plot):\n","#     if metrics[idx] == 'f1_score': # f1-score return 2 values, because labels is one-hot-encoding\n","#       train_values = [np.mean(arr) for arr in history.history[metrics[idx]]] # get mean from array values\n","#       val_values = [np.mean(arr) for arr in history.history[f'val_{metrics[idx]}']] # get mean from array values\n","#     else:\n","#       train_values = history.history[metrics[idx]]\n","#       val_values = history.history[f'val_{metrics[idx]}']\n","\n","#     # set up show plot data\n","#     axs[idx].plot(train_values, label=f'train_{metrics[idx]}')\n","#     axs[idx].plot(val_values, label=f'val_{metrics[idx]}')\n","#     axs[idx].set_title(f'{metrics[idx]} model')\n","#     axs[idx].set_xlabel('epoch')\n","#     axs[idx].set_ylabel(f'{metrics[idx]}')\n","#     axs[idx].legend()\n","\n","#   # show ploting\n","#   plt.tight_layout()\n","#   plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gazNsIXPbEJ3"},"outputs":[],"source":["def Recall(y_true, y_pred):\n","    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n","    recall = true_positives / (possible_positives + K.epsilon())\n","    return recall\n","\n","def Precision(y_true, y_pred):\n","    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n","    precision = true_positives / (predicted_positives + K.epsilon())\n","    return precision\n","\n","def F1_Score(y_true, y_pred):\n","    precision = Precision(y_true, y_pred)\n","    recall = Recall(y_true, y_pred)\n","    return 2*((precision*recall)/(precision+recall+K.epsilon()))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ncOA6FE_6NCq"},"outputs":[],"source":["# Check device running on GPU\n","if tf.config.list_physical_devices('GPU'):\n","  print('GPU is available')\n","else:\n","  print('GPU is not available (USING CPU)')\n","\n","# Compile the model\n","model.compile(optimizer=Adam(learning_rate=0.0001),\n","              loss='binary_crossentropy',\n","              metrics=['Accuracy', 'Precision', 'Recall', F1_Score])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IweFIJj_vxK7"},"outputs":[],"source":["# save the best training model\n","best_model_path = os.path.join(model_save_folder, 'best_model.keras')\n","checkpoint = ModelCheckpoint(best_model_path, monitor='val_loss', save_best_only=True, mode='min', verbose=1)\n","\n","# early stopping when there was no significant improvement in the training process\n","early_stopping = EarlyStopping(monitor='val_loss', patience=4, mode='auto')\n","\n","# training the model (without augmentation)\n","model_history = model.fit(x = train_frames_norm,\n","                          y = train_labels,\n","                          validation_data= (val_frames, val_labels),\n","                          epochs = 100,\n","                          batch_size = BATCH_SIZE,\n","                          callbacks=[checkpoint, early_stopping],\n","                          shuffle = True)\n","\n","# save the training model\n","model_save_path = os.path.join(model_save_folder, 'model.keras')\n","model.save(model_save_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n6QwIYT_9H94"},"outputs":[],"source":["# show plot model history\n","metrics = list(model_history.history.keys()) # get dictionary key\n","num_plot = int(len(metrics) / 2) # for get only train key\n","\n","_, axs = plt.subplots(1, num_plot, figsize=(30, 6)) # set canvas size\n","\n","for idx in range(num_plot):\n","  # for colab:\n","  # if metrics[idx] == 'f1_score': # f1-score return 2 values, because labels is one-hot-encoding\n","  #   train_values = [np.mean(arr) for arr in model_history.history[metrics[idx]]] # get mean from array values\n","  #   val_values = [np.mean(arr) for arr in model_history.history[f'val_{metrics[idx]}']] # get mean from array values\n","  # else:\n","  #   train_values = model_history.history[metrics[idx]]\n","  #   val_values = model_history.history[f'val_{metrics[idx]}']\n","\n","  train_values = model_history.history[metrics[idx]]\n","  val_values = model_history.history[f'val_{metrics[idx]}']\n","\n","  # set up show plot data\n","  axs[idx].plot(train_values, label=f'train_{metrics[idx]}')\n","  axs[idx].plot(val_values, label=f'val_{metrics[idx]}')\n","  axs[idx].set_title(f'{metrics[idx]} model')\n","  axs[idx].set_xlabel('epoch')\n","  axs[idx].set_ylabel(f'{metrics[idx]}')\n","  axs[idx].legend()\n","\n","# save the plot\n","save_img = os.path.join(model_save_folder, 'plotting_metrics.jpg')\n","plt.savefig(save_img)\n","\n","# show ploting\n","plt.tight_layout()\n","plt.show()\n","\n","# plot_history(model_history)"]},{"cell_type":"markdown","metadata":{"id":"-qn-TwVF2ZLy"},"source":["# Evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FjsKVEzSVWlf"},"outputs":[],"source":["# evaluate the model\n","model_eval = load_model(model_save_path, custom_objects={'F1_Score': F1_Score})\n","result_model_eval = model_eval.evaluate(test_frames, test_labels)"]},{"cell_type":"code","source":["# evaluate the best model\n","best_model = load_model(best_model_path, custom_objects={'F1_Score': F1_Score})\n","result_best_model = best_model.evaluate(test_frames, test_labels)"],"metadata":{"id":"p4U2S_pZpS8E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Model Report\n","def report_metrics_value(model, metric_key, metric_name, idx, note):\n","  for key in metric_key[:metric_name]:\n","    if key == 'f1_score':\n","      value = np.mean(model.history[key][idx])\n","    else:\n","      value = model.history[key][idx]\n","\n","    note.write('\\ttrain_{}\\t: {:.4}'.format(key, value))\n","\n","  note.write('\\n')\n","  for key in metric_key[metric_name:]:\n","    if key == 'val_f1_score':\n","      value = np.mean(model.history[key][idx])\n","    else:\n","      value = model.history[key][idx]\n","\n","    note.write('\\t{}\\t: {:.4}'.format(key, value))\n","\n","def report_eval(model, metric_key, note):\n","  for idx, value in enumerate(model):\n","    if isinstance(value, np.ndarray):\n","      value = np.mean(value)\n","\n","    note.write('\\t{}\\t: {:.4}'.format(metric_key[idx], value))\n","\n","# Save Files\n","save_report = os.path.join(model_save_folder, 'training_report.txt')\n","with open(save_report, 'w') as f:\n","  # Training report\n","  f.write(f'TRAINING REPORT📝\\n\\n')\n","  f.write(f'Image Size\\t\\t: {IMAGE_HEIGHT}(H) x {IMAGE_WIDTH}(W)\\n')\n","  f.write(f'Total Train Data\\t: {train_frames_norm.shape[0]}\\nTotal Valid Data\\t: {val_frames.shape[0]}\\nTotal Test Data\\t\\t: {test_frames.shape[0]}\\n')\n","  f.write(f'Frame Sequences\\t\\t: {SEQUENCE_COUNT}\\n')\n","  f.write(f'Batch Size\\t\\t: {BATCH_SIZE}\\n\\n')\n","\n","  f.write(f'Optimizer Name\\t: {model.optimizer.get_config()[\"name\"]}\\n')\n","  f.write('learning rate\\t: {:.5g}\\n'.format(model.optimizer.get_config()['learning_rate']))\n","\n","  config_str='\\n\\t'.join([f'{key}: {value}' for key, value in model.optimizer.get_config().items() if key != 'name' and key != 'learning_rate'])\n","  f.write(f'Optimizer Config:\\n\\t{config_str}\\n\\n')\n","\n","  f.write(f'Loss\\t: {model.loss}\\n')\n","  f.write(f'Metrics\\t: {metrics[1:num_plot]}\\n\\n')\n","\n","  f.write(f'Total Epoch\\t\\t: {model_history.params[\"epochs\"]}\\n')\n","  f.write(f'Step Per-Epoch\\t\\t: {model_history.params[\"steps\"]}\\n')\n","  try:\n","    f.write(f'Epoch Early Stopping\\t: {early_stopping.stopped_epoch}\\n')\n","  except:\n","    f.write(f'Epoch Early Stopping\\t: 0\\n')\n","\n","  idx = model_history.history['val_loss'].index(min(model_history.history['val_loss']))\n","  f.write(f'Best Model Epoch\\t: {idx+1}\\n\\n')\n","\n","  f.write('Training Model:\\n')\n","  report_metrics_value(model_history, metrics, num_plot, idx=-1, note=f)\n","\n","  f.write('\\n\\nTraining Best Model:\\n')\n","  report_metrics_value(model_history, metrics, num_plot, idx=idx, note=f)\n","\n","  # Evaluation Report\n","  f.write('\\n\\nEvaluation Model:\\n')\n","  report_eval(result_model_eval, metrics, f)\n","\n","  f.write('\\n\\nEvaluation Best Model:\\n')\n","  report_eval(result_best_model, metrics, f)"],"metadata":{"id":"wYpcqc5bppnH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# get label predict and original\n","get_data = [train_frames, val_frames, test_frames]\n","get_labels = [train_labels, val_labels, test_labels]\n","titles = ['Train', 'Validation', 'Test']\n","name_confusion = 'Last Epoch Confusion Matrix'\n","\n","fig, axes = plt.subplots(1, 3, figsize=(21, 7))\n","fig.suptitle(name_confusion, fontsize=16)\n","\n","for idx, ax in enumerate(axes):\n","  model_predict = model_eval.predict(get_data[idx])\n","  label_predict = np.argmax(model_predict, axis=1)\n","  label_original = np.argmax(get_labels[idx], axis=1)\n","  conf_matrix = confusion_matrix(label_predict, label_original) # get confusion matrix\n","\n","  sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', ax=ax)\n","  ax.set_xlabel('Predicted labels')\n","  ax.set_ylabel('True labels')\n","  ax.set_title(titles[idx])\n","  ax.set_xticklabels(['Class 0', 'Class 1'])\n","  ax.set_yticklabels(['Class 0', 'Class 1'])\n","\n","# save the plot\n","save_img = os.path.join(model_save_folder, name_confusion + '.jpg')\n","plt.savefig(save_img)\n","\n","# show plot\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"P7PC68aYZaWX"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3Ic2DY_LzNiF"},"outputs":[],"source":["# get label predict and original\n","get_data = [train_frames, val_frames, test_frames]\n","get_labels = [train_labels, val_labels, test_labels]\n","titles = ['Train', 'Validation', 'Test']\n","name_confusion = 'Best Model Confusion Matrix'\n","\n","fig, axes = plt.subplots(1, 3, figsize=(21, 7))\n","fig.suptitle(name_confusion, fontsize=16)\n","\n","for idx, ax in enumerate(axes):\n","  model_predict = best_model.predict(get_data[idx])\n","  label_predict = np.argmax(model_predict, axis=1)\n","  label_original = np.argmax(get_labels[idx], axis=1)\n","  conf_matrix = confusion_matrix(label_predict, label_original) # get confusion matrix\n","\n","  sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', ax=ax)\n","  ax.set_xlabel('Predicted labels')\n","  ax.set_ylabel('True labels')\n","  ax.set_title(titles[idx])\n","  ax.set_xticklabels(['Class 0', 'Class 1'])\n","  ax.set_yticklabels(['Class 0', 'Class 1'])\n","\n","# save the plot\n","save_img = os.path.join(model_save_folder, name_confusion + '.jpg')\n","plt.savefig(save_img)\n","\n","# show plot\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"A_TRgU2rbKbT"},"source":["# Model Prediction"]},{"cell_type":"markdown","metadata":{"id":"o1jzo6Llw7IX"},"source":["## Predict every 30 frame"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zSiSHPFa2S1T"},"outputs":[],"source":["# def frame_preprocessing(image):\n","#   image = image[:, :, [2, 1, 0]]\n","#   image = cv2.resize(image, (IMAGE_WIDTH, IMAGE_HEIGHT))\n","#   image = image.astype(np.float32)\n","#   image = image / 255.0\n","#   return image\n","\n","# def model_predict(frames, model):\n","#   get_frame = [frame_preprocessing(image) for image in frames]\n","#   get_frame = np.array(get_frame)\n","#   get_frame = np.expand_dims(get_frame, axis=0)\n","#   return model.predict(get_frame)\n","\n","# def show_predict(predict):\n","#   label = np.argmax(predict)\n","#   if label == 0:\n","#     text = 'Perilaku: Normal'\n","#   elif label == 1:\n","#     text = 'Perilaku: Pencurian'\n","#   else:\n","#     text = 'Detecting...'\n","#   return text\n","\n","# def add_text(frame, text):\n","#     font = cv2.FONT_HERSHEY_SIMPLEX\n","#     top_left_corner = (10, 30)\n","#     font_scale = 1\n","#     font_color = (0, 255, 0)\n","#     line_type = 2\n","#     cv2.putText(frame, text, top_left_corner, font, font_scale, font_color, line_type)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WxKntOyLM2nW"},"outputs":[],"source":["# # folder path\n","# folder_path = \"/content/drive/MyDrive/Skripsi/Data_Inference\"\n","\n","# # for root, _, files in os.walk(folder_path):\n","# #   for idx, get_file in enumerate(files):\n","# #     video_path = os.path.join(root, get_file)\n","# #     print(video_path)\n","# # ------------------------------------------------------------\n","\n","# # video path\n","# # video_path = os.path.join(folder_path, 'Test_Video', 'Test_Video.mp4')\n","# # video_path = '/content/drive/MyDrive/Skripsi/Dataset/Normal/Ritel/normal (5).mp4'\n","# video_path = '/content/drive/MyDrive/Skripsi/Data_Inference/pencurian (3).mp4'\n","\n","# # Load trained model\n","# model_path = os.path.join(save_file_path, 'Model', '24-05-09', 'SelfBuild_CNN-LSTM(15_45)', 'best_model.keras')\n","\n","# cap = cv2.VideoCapture(video_path)\n","# model = load_model(model_path, custom_objects={'F1_Score': F1_Score})\n","# frames = []\n","# text = 'Detecting...'\n","\n","# frame_width = int(cap.get(3))\n","# frame_height = int(cap.get(4))\n","# fps = int(cap.get(cv2.CAP_PROP_FPS))\n","\n","# output_path = os.path.join(folder_path, 'Result', os.path.basename(video_path))\n","# frame2video = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n","\n","# while(True):\n","#   ret, frame = cap.read()\n","\n","#   if not ret:\n","#     break;\n","\n","#   frames.append(frame)\n","#   if len(frames) == SEQUENCE_COUNT:\n","#     prediction = model_predict(frames, model)\n","#     text = show_predict(prediction)\n","#     print(text)\n","#     frames = []\n","\n","#   add_text(frame, text)\n","#   frame2video.write(frame)\n","\n","# cap.release()\n","# frame2video.release()"]},{"cell_type":"markdown","metadata":{"id":"8OOY_9cqxXIp"},"source":["## Predict only 30 frame"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D3MlXPRb0YtT"},"outputs":[],"source":["# def frame_video(video_path, resize=(320, 240), sequence_count=20):\n","#   video_reader = cv2.VideoCapture(video_path) # get video\n","#   frames_count = int(video_reader.get(cv2.CAP_PROP_FRAME_COUNT)) # count of frame\n","#   skip_frames = max(frames_count//sequence_count, 1) # set the value to 1 if the quotient is negative\n","#   frames = []\n","\n","#   for frame_counter in range(sequence_count):\n","#     video_reader.set(cv2.CAP_PROP_POS_FRAMES, frame_counter * skip_frames)\n","#     success, frame = video_reader.read()\n","\n","#     # check if Video frame is not successfully read then break the loop\n","#     if not success:\n","#         break\n","\n","#     frame = frame[:, :, [2, 1, 0]] # convert image format (BGR->RGB)\n","#     frame = cv2.resize(frame, resize) # resize image\n","#     frame = frame.astype(np.float32)\n","#     frame = frame / 255.0\n","#     frames.append(frame)\n","\n","#   video_reader.release()\n","#   return frames"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vorWeo2mxgcY"},"outputs":[],"source":["# folder_path = \"/content/drive/MyDrive/Skripsi/Data_Inference\"\n","# video_path = folder_path + '/normal (2).mp4'\n","# model_path = os.path.join(save_file_path, 'Model', '24-05-16', 'SelfBuild_CNN-LSTM(14_50)', 'best_model.keras')\n","\n","# frames = frame_video(video_path, resize=(IMAGE_WIDTH, IMAGE_HEIGHT), sequence_count=SEQUENCE_COUNT)\n","# frames = np.array(frames)\n","# frames = np.expand_dims(frames, axis=0)\n","\n","# model = load_model(model_path, custom_objects={'F1_Score': F1_Score})\n","# predict = model.predict(frames)\n","# predict = np.argmax(predict)\n","\n","# if predict == 0:\n","#   label = 'Normal'\n","# else:\n","#   label = 'Pencurian'\n","\n","# print(label)"]},{"cell_type":"markdown","source":["# Convert model format .keras to .H5"],"metadata":{"id":"s8ka14zrdywc"}},{"cell_type":"code","source":["# path_model = '/content/drive/MyDrive/Skripsi/File_Save/Model/best_model.keras'\n","# test_model = load_model(path_model, custom_objects={''F1_Score': F1_Score})\n","# test_model.save('/content/drive/MyDrive/Skripsi/File_Save/Model/test_model.h5')"],"metadata":{"id":"JIG6eh_Rd7Jf"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"collapsed_sections":["6V_dmbRm00Q8","A_TRgU2rbKbT","o1jzo6Llw7IX"],"provenance":[],"gpuType":"L4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}